{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Originally written for my Advanced Analytics Programming class at The University of Texas at Austin, this article is meant to quickly show some neat things Machine Learning can provide on the wonderful world of wine. This article assumes a basic knowledge of Machine Leaning, but feel free to browse through the insights.\n",
    "\n",
    "I'll be doing an analysis on the [Wine Quality Data Set](http://archive.ics.uci.edu/ml/datasets/Wine+Quality) provided by the UCI Machine Learning Repository. I'm not a wine expert by any means, but I wanted to see what really goes into a quality wine for my next purchase. The dataset contains data about 1,599 red wines and 4,898 white wines. Each wine has these features:  \n",
    "\n",
    "* **Fixed acidity** - Acidity contained in the grapes\n",
    "* **Volatile acidity** - Acidity caused by fermentation of the wine\n",
    "* **Citric acid** - Catalyst for fermentation\n",
    "* **Residual sugar** - yum\n",
    "* **Chlorides** - Chlorine compound who's content typically determined by wines terroir (terr-wah - or where the wine was * grown, important in determining wine origins)\n",
    "* **Free sulfur dioxide** - Buffer against microbes and oxidation\n",
    "* **Total sulfur dioxide** - used as a preservative\n",
    "* **Density** - Weight per liter\n",
    "* **pH** - base or acid\n",
    "* **Sulphates** - Preservatives\n",
    "* **Alcohol** - the fun part\n",
    "* **Quality** - median of 3 evaluations made by wine experts\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Imports\n",
    "\n",
    "Each of these imports is a highly valuable resource for machine learning. I recommend looking into these: \n",
    "\n",
    "* [pandas - Data Analysis Library](http://pandas.pydata.org/)\n",
    "* [patsy - Describing statistical models in Python](https://patsy.readthedocs.io/en/latest/)\n",
    "* [StatsModels: Statistics in Python](http://www.statsmodels.org/stable/index.html)\n",
    "* [scikit-learn: machine learning in Python](http://scikit-learn.org/stable/)\n",
    "\n",
    "I've also touched on what I use each import for in my comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "# Data analysis tools\n",
    "import pandas as pd # Powerful data analysis library\n",
    "from pandas import DataFrame, Series # Easy access to pandas datastructures\n",
    "from patsy import dmatrices # Simple way to transform data for analysis\n",
    "from sklearn.model_selection import train_test_split # Split data for training and testing\n",
    "\n",
    "# Machine learning tools\n",
    "import statsmodels.api as sm # Where OLS lives\n",
    "from sklearn.linear_model import LogisticRegression # For running a logistic regress\n",
    "from sklearn import tree # For creating a Decision Tree\n",
    "from sklearn import metrics # For finding out how accurate everything is\n",
    "\n",
    "# Other\n",
    "import os\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Assembly\n",
    "\n",
    "I'm a big fan of documentation, so I guess I'll keep commenting (nearly) every line. Here we begin to assemble our dataset. We don't have much cleanup to do, but the data was provided with a funky seperator and we need to label each whine as red or white. We can then combine our datasets into a unified dataset (mainly for later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red wines:  1599\n",
      "White wines:  4898\n",
      "Total wines:  6497\n"
     ]
    }
   ],
   "source": [
    "# Change all names to include underscores for patsy formulas\n",
    "names = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'color']\n",
    "\n",
    "# Load red wines\n",
    "dfRed = pd.read_csv('data/winequality-red.csv', sep=\";\")\n",
    "dfRed['color'] = 'red'\n",
    "dfRed.columns = names\n",
    "\n",
    "# Load white wines\n",
    "dfWhite = pd.read_csv('data/winequality-white.csv', sep=\";\")\n",
    "dfWhite['color'] = 'white'\n",
    "dfWhite.columns = names\n",
    "\n",
    "# Create master dataframe\n",
    "df = pd.concat([dfRed, dfWhite])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Get some basic information\n",
    "\n",
    "print \"Red wines: \", len(dfRed)\n",
    "print \"White wines: \", len(dfWhite)\n",
    "print \"Total wines: \", len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression\n",
    "\n",
    "First, we're going to be running an [Ordinary Least Squares Regression](https://en.wikipedia.org/wiki/Ordinary_least_squares#Classical_linear_regression_model) on our data, attempting to find the quality of a wine from all other factors. This will allow us to see which variables are important to the quality of the wine. We can also see which variables are the most significant, and remove those that aren't.\n",
    "\n",
    "Patsy, which is what we'll use for our design matrices, accepts a '[formula-like](http://patsy.readthedocs.io/en/latest/API-reference.html)' argument so it can separate our data for us. To create our formula, we're going to regress quality on every variable except color (let's look at purely quantifiable variables for now) and quality (for obvious reasons). Since dfRed and dfWhite contain the same feature names, and df is just dfRed and dfWhite combined, we can use the columns in df to create our formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quality ~ 0 + fixed_acidity + volatile_acidity + citric_acid + residual_sugar + chlorides + free_sulfur_dioxide + total_sulfur_dioxide + density + pH + sulphates + alcohol\n"
     ]
    }
   ],
   "source": [
    "# Exclude color (categorical) and quality from regressing on quality\n",
    "traitsToExclude = ['color', 'quality']\n",
    "\n",
    "# Generate formula\n",
    "initialFormula = 'quality ~ 0 + ' + \" + \".join([column for column in df if column not in traitsToExclude])\n",
    "print initialFormula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Wines\n",
    "\n",
    "Now that we have our formula, it's time to create a regression. I've defined a simple function that does it all in one step - it will regress a given formula on a given DataFrame. Inside the function, there's a few moving pieces. Let's split the data into an X and y dataframe so that it can be regressed. We then split that data into training and testing data, fit the model, and return our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.987\n",
      "Model:                            OLS   Adj. R-squared:                  0.987\n",
      "Method:                 Least Squares   F-statistic:                     7731.\n",
      "Date:                Thu, 11 May 2017   Prob (F-statistic):               0.00\n",
      "Time:                        00:01:52   Log-Likelihood:                -1102.4\n",
      "No. Observations:                1119   AIC:                             2227.\n",
      "Df Residuals:                    1108   BIC:                             2282.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "fixed_acidity            0.0107      0.019      0.556      0.579      -0.027       0.048\n",
      "volatile_acidity        -1.2014      0.145     -8.304      0.000      -1.485      -0.918\n",
      "citric_acid             -0.2845      0.177     -1.609      0.108      -0.632       0.062\n",
      "residual_sugar           0.0006      0.015      0.042      0.967      -0.029       0.031\n",
      "chlorides               -1.8694      0.503     -3.718      0.000      -2.856      -0.883\n",
      "free_sulfur_dioxide      0.0064      0.003      2.409      0.016       0.001       0.012\n",
      "total_sulfur_dioxide    -0.0039      0.001     -4.380      0.000      -0.006      -0.002\n",
      "density                  4.6683      0.743      6.285      0.000       3.211       6.126\n",
      "pH                      -0.5557      0.191     -2.916      0.004      -0.930      -0.182\n",
      "sulphates                0.8421      0.132      6.361      0.000       0.582       1.102\n",
      "alcohol                  0.3019      0.021     14.598      0.000       0.261       0.342\n",
      "==============================================================================\n",
      "Omnibus:                       18.922   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.011\n",
      "Skew:                          -0.159   Prob(JB):                     8.27e-07\n",
      "Kurtosis:                       3.707   Cond. No.                     2.40e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.4e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "def ols(data, formula):\n",
    "    \"\"\"\n",
    "    ols(data, formula) runs an ordinary least squares regression on a set of data given a formula\n",
    "    data - pandas.DataFrame\n",
    "    formula - patsy formula-like\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load design matrix\n",
    "    y, X = dmatrices(formula, data=data, return_type='dataframe')\n",
    "\n",
    "    # Fit model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    result = sm.OLS(y_train, X_train).fit()\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = ols(dfRed, initialFormula)\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good - but let's take a look at those p-values. It's clear that many of these variables aren't very significant towards quality, and so we can remove them from our regression.\n",
    "\n",
    "| **Item** | **P-Value** |\n",
    "| ----- | ----- |\n",
    "| Fixed Acidity | 0.579 |\n",
    "| Citric Acid | 0.108 |\n",
    "| Residual Sugar | 0.967 |\n",
    "| Free Sulfur Dioxide | 0.016 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.987\n",
      "Model:                            OLS   Adj. R-squared:                  0.987\n",
      "Method:                 Least Squares   F-statistic:                 1.208e+04\n",
      "Date:                Thu, 11 May 2017   Prob (F-statistic):               0.00\n",
      "Time:                        00:28:35   Log-Likelihood:                -1107.5\n",
      "No. Observations:                1119   AIC:                             2229.\n",
      "Df Residuals:                    1112   BIC:                             2264.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "volatile_acidity        -1.1082      0.122     -9.116      0.000      -1.347      -0.870\n",
      "chlorides               -2.0664      0.477     -4.330      0.000      -3.003      -1.130\n",
      "total_sulfur_dioxide    -0.0027      0.001     -4.308      0.000      -0.004      -0.001\n",
      "density                  4.3390      0.469      9.250      0.000       3.419       5.259\n",
      "pH                      -0.4287      0.136     -3.147      0.002      -0.696      -0.161\n",
      "sulphates                0.8430      0.131      6.411      0.000       0.585       1.101\n",
      "alcohol                  0.2954      0.020     14.772      0.000       0.256       0.335\n",
      "==============================================================================\n",
      "Omnibus:                       19.144   Durbin-Watson:                   2.022\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.903\n",
      "Skew:                          -0.181   Prob(JB):                     1.44e-06\n",
      "Kurtosis:                       3.668   Cond. No.                     1.58e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.58e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "exemptions = ['color', 'quality', 'fixed_acidity', 'citric_acid', 'residual_sugar', 'free_sulfur_dioxide']\n",
    "newFormula = 'quality ~ 0 + ' + \" + \".join([column for column in df if column not in exemptions])\n",
    "result = ols(dfRed, newFormula)\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Even after removing those four variables, we have an R-squared value of 0.987. We can also observe our result parameters here, and draw some insights regarding a white wine. \"Importance\" is a measure derived from the coefficient - the further from 0, the more important.\n",
    "\n",
    "| **Variable** | **Coefficient** | **Insight** | **Importance** |\n",
    "| ------------ | --------------- | ----------- | ---------------- |\n",
    "| Volatile Acidity | -1.1082 | The **higher** your volatile acidity, the **lower** your quality. | Medium |\n",
    "| Chlorides | -2.0665 | The **higher** your chlorides, the **lower** your quality. | High |\n",
    "| Total Sulfure Dioxide | -0.0027 | The **higher** your total sulfur dioxide, the **lower** your quality. | Low |\n",
    "| Density | 4.3390 | The **higher** your density, the **higher** your quality. | High |\n",
    "| pH | -0.4287 | The **higher** your pH, the **lower** your quality. | Medium-Low |\n",
    "| Sulphates | 0.8430 | The **higher** your sulphates, the **higher** your quality. | Medium-Low |\n",
    "| Alcohol | 0.2954 | The **higher** your alcohol content, the **higher** your quality. | Medium-Low |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Wines\n",
    "\n",
    "This process is essentially the same as our regression for red wine, but with our white wine data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.984\n",
      "Model:                            OLS   Adj. R-squared:                  0.983\n",
      "Method:                 Least Squares   F-statistic:                 1.853e+04\n",
      "Date:                Thu, 11 May 2017   Prob (F-statistic):               0.00\n",
      "Time:                        00:28:38   Log-Likelihood:                -3933.1\n",
      "No. Observations:                3428   AIC:                             7888.\n",
      "Df Residuals:                    3417   BIC:                             7956.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "fixed_acidity           -0.0547      0.018     -2.986      0.003      -0.091      -0.019\n",
      "volatile_acidity        -2.0939      0.135    -15.483      0.000      -2.359      -1.829\n",
      "citric_acid             -0.0507      0.115     -0.441      0.659      -0.276       0.175\n",
      "residual_sugar           0.0276      0.003      8.880      0.000       0.022       0.034\n",
      "chlorides               -1.2006      0.680     -1.766      0.078      -2.534       0.133\n",
      "free_sulfur_dioxide      0.0038      0.001      3.809      0.000       0.002       0.006\n",
      "total_sulfur_dioxide    -0.0005      0.000     -1.004      0.316      -0.001       0.000\n",
      "density                  2.0509      0.424      4.836      0.000       1.219       2.883\n",
      "pH                       0.1571      0.101      1.559      0.119      -0.041       0.355\n",
      "sulphates                0.3709      0.118      3.155      0.002       0.140       0.601\n",
      "alcohol                  0.3744      0.014     27.576      0.000       0.348       0.401\n",
      "==============================================================================\n",
      "Omnibus:                       87.955   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              203.502\n",
      "Skew:                           0.064   Prob(JB):                     6.46e-45\n",
      "Kurtosis:                       4.187   Cond. No.                     7.99e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.99e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Recreate master formula\n",
    "traitsToExclude = ['color', 'quality']\n",
    "initialFormula = 'quality ~ 0 + ' + \" + \".join([column for column in df if column not in traitsToExclude])\n",
    "\n",
    "result = ols(dfWhite, initialFormula)\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, right off the bat we can see that the variables with a higher p-value are different for white whines than for red wines.\n",
    "\n",
    "| **Item** | **P-Value** |\n",
    "| ----- | ----- |\n",
    "| Citric acid | 0.659 |\n",
    "| Chlorides | 0.078 |\n",
    "| Total sulfur dioxide | 0.316 |\n",
    "| pH | 0.119 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                quality   R-squared:                       0.983\n",
      "Model:                            OLS   Adj. R-squared:                  0.983\n",
      "Method:                 Least Squares   F-statistic:                 2.909e+04\n",
      "Date:                Thu, 11 May 2017   Prob (F-statistic):               0.00\n",
      "Time:                        00:28:42   Log-Likelihood:                -3936.7\n",
      "No. Observations:                3428   AIC:                             7887.\n",
      "Df Residuals:                    3421   BIC:                             7930.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "fixed_acidity          -0.0693      0.016     -4.352      0.000      -0.101      -0.038\n",
      "volatile_acidity       -2.1379      0.130    -16.467      0.000      -2.392      -1.883\n",
      "residual_sugar          0.0268      0.003      8.972      0.000       0.021       0.033\n",
      "free_sulfur_dioxide     0.0032      0.001      3.928      0.000       0.002       0.005\n",
      "density                 2.4150      0.199     12.154      0.000       2.025       2.805\n",
      "sulphates               0.3771      0.115      3.271      0.001       0.151       0.603\n",
      "alcohol                 0.3879      0.012     32.236      0.000       0.364       0.412\n",
      "==============================================================================\n",
      "Omnibus:                       86.141   Durbin-Watson:                   2.038\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              193.739\n",
      "Skew:                           0.080   Prob(JB):                     8.51e-43\n",
      "Kurtosis:                       4.153   Cond. No.                         652.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Optimize result\n",
    "exemptions = ['color', 'quality', 'citric_acid', 'chlorides', 'total_sulfur_dioxide', 'pH']\n",
    "newFormula = 'quality ~ 0 + ' + \" + \".join([column for column in df if column not in exemptions])\n",
    "result = ols(dfWhite, newFormula)\n",
    "print result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. Our R-squared value actually went down by 0.001, but that's a good sign that we're not overfitting. Let's take a look at our white wine data.\n",
    "\n",
    "| **Variable** | **Coefficient** | **Insight** | **Importance** |\n",
    "| ------------ | --------------- | ----------- | ---------------- |\n",
    "| Fixed Acidity | -0.0693 | The **higher** your fixed acidity, the **lower** your quality. | Low |\n",
    "| Volatile Acidity | -2.1379 | The **higher** your volatile acidity, the **lower** your quality. | High |\n",
    "| Residual Sugar | 0.0268 | The **higher** your residual sugar, the **higher** your quality. | Low |\n",
    "| Free Sulfur Dioxide | 0.0032 | The **higher** your free sulfur dioxide, the **higher** your quality. | Low |\n",
    "| Density | 2.4150 | The **higher** your density, the **higher** your quality. | High |\n",
    "| Sulphates | 0.3771 | The **higher** your sulphates, the **higher** your quality. | Medium-Low |\n",
    "| Alcohol | 0.3879 | The **higher** your alcohol content, the **higher** your quality. | Medium-Low |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "\n",
    "What are our key takeaways from this?\n",
    "* Red wine makers should focus on **increasing density**, **decreasing volatile acidity**, and **decreasing chlorides**.\n",
    "* White wine makers should focus on **increasing density** (but not the point of red wine), **decreasing volatile acidity**, and **increasing alcohol content**.\n",
    "* Who likes white wine anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine color from other traits\n",
    "\n",
    "# Create formula to identify color\n",
    "formula = \"color ~ 0 + \" + \" + \".join([column for column in df if column != 'color'])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up design matrices\n",
    "Y, X = dmatrices(formula, data=df, return_type=\"dataframe\")\n",
    "# Since color is a binary categorical variable, we can look just for red\n",
    "y = Y['color[red]'].values\n",
    "\n",
    "# Split into test data and fit model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "model = LogisticRegression()\n",
    "result = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score model - nice!\n",
    "prediction = model.predict(X_test)\n",
    "metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What's important?\n",
    "weights = Series(model.coef_[0], index=X.columns.values)\n",
    "weights.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can we make a chart to figure out how great a wine is?\n",
    "traitsToExclude = ['color', 'quality']\n",
    "formula = 'C(quality) ~ 0 + C(color) + ' + \" + \".join([column for column in df if column not in traitsToExclude])\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idf in [dfRed, dfWhite]:\n",
    "    nums = {}\n",
    "    ratings = idf.quality.unique()\n",
    "    for num in ratings:\n",
    "        Y, X = dmatrices(formula, idf, return_type='dataframe')\n",
    "        y = Y[\"C(quality)[%d]\" % num].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "        model = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "        result = model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        nums[num] = metrics.accuracy_score(y_test, prediction)\n",
    "    print nums\n",
    "    numdf = DataFrame(nums.items(), columns=[\"Rating\", \"Accuracy\"])\n",
    "    numdf.plot(x=\"Rating\", y=\"Accuracy\").set_xlabel(\"%s Ratings\" % idf.color.unique()[0].title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(model, feature_names=X.columns)\n",
    "os.system('dot -Tpng tree.dot -o tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![9](tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Red Qualities\"\n",
    "print dfRed['quality'].value_counts()\n",
    "print \"\"\n",
    "print \"White Qualities\"\n",
    "print dfWhite['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
